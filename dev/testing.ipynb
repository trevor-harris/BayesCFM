{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d87ee-a18f-402b-8ce0-2fef2c1ed54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import bayescfm as bcfm\n",
    "\n",
    "# 1) Dummy data\n",
    "class WhiteNoise(Dataset):\n",
    "    def __init__(self, n=512, shape=(3,32,32), seed=0):\n",
    "        g = torch.Generator().manual_seed(seed)\n",
    "        C,H,W = shape\n",
    "        self.x = (torch.rand(n, C, H, W, generator=g)*2-1).float()\n",
    "        self.y = torch.randint(0, 10, (n,), generator=g)\n",
    "    def __len__(self): return self.x.size(0)\n",
    "    def __getitem__(self, i): return self.x[i], self.y[i]\n",
    "\n",
    "loader = DataLoader(WhiteNoise(), batch_size=64, shuffle=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f674f86-8e21-40e1-b9ca-65083551b265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] step      10  loss=1.1652\n",
      "[epoch 3] step      20  loss=1.1688\n",
      "[epoch 4] step      30  loss=1.1222\n",
      "[epoch 5] step      40  loss=0.9456\n"
     ]
    }
   ],
   "source": [
    "# 2) Plain CFM training (OT path)\n",
    "model = bcfm.UNetCFM(\n",
    "    in_channels=3, out_channels=3, model_channels=64,\n",
    "    channel_mult=(1,2,2), num_res_blocks=1,\n",
    "    attn_resolutions=(16,), num_heads=4,\n",
    "    num_classes=10, class_dropout_prob=0.1,\n",
    ")\n",
    "\n",
    "ema_model = bcfm.train_cfm(model, loader, epochs=5, lr=1e-3, device=device, log_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9928d4a5-b5b0-487a-acfb-3fe2948925f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] step      10 total=1.1469  cfm=1.1468  curl=0.0000  mono=1.0478\n",
      "[epoch 3] step      20 total=0.9570  cfm=0.9569  curl=0.0000  mono=1.1282\n",
      "[epoch 4] step      30 total=0.9619  cfm=0.9618  curl=0.0000  mono=1.1074\n",
      "[epoch 5] step      40 total=0.9354  cfm=0.9353  curl=0.0000  mono=1.0598\n"
     ]
    }
   ],
   "source": [
    "# 3) Regularized training (autodiff gradient-field penalties)\n",
    "model = bcfm.UNetCFM(\n",
    "    in_channels=3, out_channels=3, model_channels=64,\n",
    "    channel_mult=(1,2,2), num_res_blocks=1,\n",
    "    attn_resolutions=(16,), num_heads=4,\n",
    "    num_classes=10, class_dropout_prob=0.1,\n",
    ")\n",
    "\n",
    "ema_reg = bcfm.train_cgm(\n",
    "    model, loader, epochs=5, lr=1e-3, device=device,\n",
    "    lambda_curl=1e-4, \n",
    "    lambda_mono=1e-4,\n",
    "    probes=1,  \n",
    "    pool_factor=None,\n",
    "    probe_dist=\"rademacher\", \n",
    "    orthogonalize=True,\n",
    "    penalty_train_flag=False,\n",
    "    normalize_curl=False,\n",
    "    log_every = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828d8ae3-2104-4f10-856f-37d419492841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] step      10 total=1.4534  cfm=1.4533  curl=0.0002  mono=0.6938  (SG-MCMC sghmc, eta=2.00e-06, T=0.1)\n",
      "[epoch 3] step      20 total=1.4558  cfm=1.4557  curl=0.0003  mono=0.6935  (SG-MCMC sghmc, eta=2.00e-06, T=0.1)\n",
      "[epoch 4] step      30 total=1.4667  cfm=1.4666  curl=0.0003  mono=0.6971  (SG-MCMC sghmc, eta=2.00e-06, T=0.1)\n",
      "[epoch 5] step      40 total=1.4561  cfm=1.4560  curl=0.0002  mono=0.6961  (SG-MCMC sghmc, eta=2.00e-06, T=0.1)\n",
      "[epoch 7] step      50 total=1.4595  cfm=1.4594  curl=0.0003  mono=0.6938  (SG-MCMC sghmc, eta=2.00e-06, T=0.1)\n",
      "[epoch 8] step      60 total=1.4695  cfm=1.4695  curl=0.0002  mono=0.6963  (SG-MCMC sghmc, eta=2.00e-06, T=0.1)\n",
      "[epoch 9] step      70 total=1.4621  cfm=1.4620  curl=0.0002  mono=0.7010  (SG-MCMC sghmc, eta=2.00e-06, T=0.1)\n",
      "[epoch 10] step      80 total=1.4795  cfm=1.4795  curl=0.0003  mono=0.7039  (SG-MCMC sghmc, eta=2.00e-06, T=0.1)\n"
     ]
    }
   ],
   "source": [
    "model = bcfm.UNetCFM(\n",
    "    in_channels=3, out_channels=3, model_channels=64,\n",
    "    channel_mult=(1,2,2), num_res_blocks=1,\n",
    "    attn_resolutions=(16,), num_heads=4,\n",
    "    num_classes=10, class_dropout_prob=0.1,\n",
    ")\n",
    "\n",
    "ema_bayes, posterior = bcfm.train_cgm_bayes(\n",
    "    model, loader, epochs=10, lr=2e-3, device=device,\n",
    "    lambda_curl=1e-4, lambda_mono=1e-4,\n",
    "    probes=1, \n",
    "    sgmcmc_enable=True, sgmcmc_alg=\"sghmc\",\n",
    "    sgmcmc_eta=2e-6, sgmcmc_temperature=0.1, sgmcmc_friction=0.2,\n",
    "    sgmcmc_collect=True, sgmcmc_burnin_steps=100, sgmcmc_thin=5, sgmcmc_max_samples=10,\n",
    "    return_posterior=True,\n",
    "    log_every = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b036482b-523b-4eea-84ce-75d0ee19a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] step      10 total=1.1435  cfm=1.1434  curl=0.0000  mono=0.9787\n",
      "[epoch 3] step      20 total=0.8632  cfm=0.8631  curl=0.0000  mono=1.1182\n",
      "[epoch 4] step      30 total=1.0151  cfm=1.0150  curl=0.0000  mono=1.0077\n",
      "[epoch 5] step      40 total=0.8965  cfm=0.8964  curl=0.0000  mono=1.0472\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "call fit() before sampling models",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     26\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m10\u001b[39m,(\u001b[38;5;241m4\u001b[39m,))\n\u001b[0;32m---> 27\u001b[0m lap_models \u001b[38;5;241m=\u001b[39m \u001b[43mlap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/climate/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BayesCFM/bayescfm/posterior/laplace.py:376\u001b[0m, in \u001b[0;36mLaplaceCFM.posterior_sample\u001b[0;34m(self, n, device, seed, eval_mode)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mposterior_sample\u001b[39m(\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m     eval_mode: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    370\u001b[0m ):\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    Return a list of `n` independent model draws from the Laplace posterior.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    Each draw is a deep-copied nn.Module with a sampled state_dict loaded.\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    Requires `fit()` to have been called.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_fitted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcall fit() before sampling models\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m         torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;28mint\u001b[39m(seed))\n",
      "\u001b[0;31mAssertionError\u001b[0m: call fit() before sampling models"
     ]
    }
   ],
   "source": [
    "model = bcfm.UNetCFM(\n",
    "    in_channels=3, out_channels=3, model_channels=64,\n",
    "    channel_mult=(1,2,2), num_res_blocks=1,\n",
    "    attn_resolutions=(16,), num_heads=4,\n",
    "    num_classes=10, class_dropout_prob=0.1,\n",
    ")\n",
    "\n",
    "# ema_lap = bcfm.train_cgm(\n",
    "#     model, loader, epochs=5, lr=1e-3, device=device,\n",
    "#     lambda_curl=1e-4, \n",
    "#     lambda_mono=1e-4,\n",
    "#     probes=1,  \n",
    "#     pool_factor=None,\n",
    "#     probe_dist=\"rademacher\", \n",
    "#     orthogonalize=True,\n",
    "#     penalty_train_flag=False,\n",
    "#     normalize_curl=False,\n",
    "#     log_every = 10\n",
    "# )\n",
    "\n",
    "lap = bcfm.LaplaceCFM(model, mode='last_layer')  # or approx=\"last_layer\"\n",
    "lap.fit(loader, device=device)\n",
    "lap_models = lap.posterior_sample(5, device=device, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adad09f7-3018-46b8-828b-9e763a70aefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_samp[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3309e8bb-d6c4-428c-89ff-31d53787a10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
